{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfJ9Tx8Em6g0cGcQFo4gS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoYongJIn/YongJin-Repository/blob/main/Transfer_learning_(Image_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XeLe1R7iHsKp",
        "outputId": "cd69d9e9-ae7f-4ff3-98ce-b2f2c7138c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "DIEoEf8b7Y3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 이미지 폴더 경로 설정\n",
        "carrot_folder = '/content/drive/MyDrive/Colab Notebooks/Images/Carrots/'\n",
        "rocket_folder = '/content/drive/MyDrive/Colab Notebooks/Images/Rockets/'\n",
        "\n",
        "# 이미지 불러오기 및 레이블링\n",
        "data = []  # 데이터를 저장할 리스트\n",
        "labels = []  # 레이블을 저장할 리스트\n",
        "\n",
        "# 당근 이미지 불러오기 및 레이블링\n",
        "for filename in os.listdir(carrot_folder):\n",
        "    img = cv2.imread(os.path.join(carrot_folder, filename))\n",
        "    if img is not None:\n",
        "        data.append(img)\n",
        "        labels.append(0)  # 당근을 '0'으로 레이블링\n",
        "\n",
        "# 로켓 이미지 불러오기 및 레이블링\n",
        "for filename in os.listdir(rocket_folder):\n",
        "    img = cv2.imread(os.path.join(rocket_folder, filename))\n",
        "    if img is not None:\n",
        "        data.append(img)\n",
        "        labels.append(1)  # 로켓을 '1'으로 레이블링\n"
      ],
      "metadata": {
        "id": "nTosrVOBIArl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터를 같은 크기로 일치 시키고 원활히 학습시키기위해 0부터 1사이의 값으로 픽셀값을 정규화시키는 과정입니다.\n",
        "resize_dim = (224, 224)  # 예를 들어, 이미지의 크기를 224x224로 설정합니다.\n",
        "\n",
        "resized_data = []  # 크기가 조정된 이미지를 저장할 리스트\n",
        "normalized_data = []  # 정규화된 이미지를 저장할 리스트\n",
        "\n",
        "for img in data:\n",
        "    # 이미지 크기 조정\n",
        "    resized_img = cv2.resize(img, resize_dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 색상 공간 변환 (예: RGB to GRAY, if needed)\n",
        "    # converted_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)  # 예를 들어, 회색조로 변환\n",
        "\n",
        "    # 이미지 정규화: 픽셀 값을 [0, 1] 범위로 조정\n",
        "    normalized_img = resized_img / 255.0\n",
        "\n",
        "    # 결과 저장\n",
        "    resized_data.append(resized_img)\n",
        "    normalized_data.append(normalized_img)\n",
        "\n",
        "# 변환된 데이터를 NumPy 배열로 변환\n",
        "import numpy as np\n",
        "resized_data = np.array(resized_data)\n",
        "normalized_data = np.array(normalized_data)\n"
      ],
      "metadata": {
        "id": "JgjSxMev3xh1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 Training Set, Validation Set, Test Set으로 분할 합니다.(검증데이터(파라미터를 정한다),테스트데이터셋을 각각 10%씩 할당했습니다.)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 전체 데이터를 훈련 데이터와 테스트 데이터로 분할 (테스트 데이터는 전체의 10%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.1, random_state=42, stratify=labels)\n",
        "\n",
        "# 훈련 데이터를 다시 훈련 데이터와 검증 데이터로 분할 (검증 데이터는 훈련 데이터의 11.1% - 전체의 10%를 의미)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1111, random_state=42, stratify=y_train)\n",
        "\n",
        "# 결과 확인\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R50vLvfE3xkC",
        "outputId": "cee1a9d0-08bd-46bb-ee11-47484ea70761"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (244, 224, 224, 3)\n",
            "Validation data shape: (31, 224, 224, 3)\n",
            "Testing data shape: (31, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(y_train))"
      ],
      "metadata": {
        "id": "ulr6IahWTa98"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# y_train, y_val, y_test를 NumPy 배열로 변환(TensorFlow와 호환하기 위해서 array로 해줍니다.)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "nL55rGQzUp_8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# VGG 스타일 네트워크 정의\n",
        "def build_vgg(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1024, activation='relu'))  # 유닛 수를 4096에서 1024로 줄임\n",
        "    model.add(layers.Dense(512, activation='relu'))   # 유닛 수를 4096에서 512로 줄임\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))  # 출력 레이어의 유닛 수는 클래스 수에 맞춤\n",
        "\n",
        "    return model\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])  # 예: (224, 224, 3) 적절한 값으로 변경해야 함\n",
        "num_classes = len(set(y_train))  # 클래스 개수\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "vgg_model = build_vgg(input_shape, num_classes)\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tm5wM7vPS8tw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련 (batch_size를 32로 했더니 colab 메모리 한도를 초과하여 배치의 크기를 8로 줄여서 실행합니다.)\n",
        "vgg_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# 모델 평가\n",
        "vgg_model.evaluate(X_test, y_test, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KfTqqAP1Ynos",
        "outputId": "6df7f882-dbe8-4ab8-e6d1-fe838bbd4aa7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 323s 39s/step - loss: 0.0324 - accuracy: 0.9877 - val_loss: 0.1351 - val_accuracy: 0.9355\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 302s 37s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9355\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 295s 37s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9032\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 312s 39s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9355\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 305s 38s/step - loss: 9.8987e-04 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9032\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 312s 39s/step - loss: 5.8760e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9032\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 295s 37s/step - loss: 4.4015e-04 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9032\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 305s 38s/step - loss: 2.6664e-04 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9032\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 305s 38s/step - loss: 2.3249e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9032\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 295s 37s/step - loss: 1.5250e-04 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9032\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4321 - accuracy: 0.9032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4320564568042755, 0.9032257795333862]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습시간이 오래걸리기 때문에 학습된 모델과 파라미터를 저장합니다.\n",
        "\n",
        "# TensorFlow SavedModel 형식으로 전체 모델 저장\n",
        "vgg_model.save('saved_model', save_format='tf')"
      ],
      "metadata": {
        "id": "VASojzEsqvl7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# 데이터를 불러오고 전처리합니다.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# ResNet Block 정의\n",
        "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride)(x)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    else:\n",
        "        shortcut = x\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Add()([shortcut, x])\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# ResNet 모델 구조 만들기\n",
        "def build_resnet(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, 7, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 128, stride=2)\n",
        "    x = resnet_block(x, 256, stride=2)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "model = build_resnet((32, 32, 3), 10)\n",
        "model.compile(optimizer=keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "model.evaluate(x_test, y_test, batch_size=32)\n",
        "\n",
        "# resnet은 학습하는데 시간이 매우 오래걸렸습니다."
      ],
      "metadata": {
        "id": "AJujbwwZZQuL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}