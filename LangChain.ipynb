{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVxnQBdvZU42Jov+qmpCUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoYongJIn/YongJin-Repository/blob/main/%08LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XakH-RL4bkcp"
      },
      "outputs": [],
      "source": [
        "# 문서 검색 챗봇 만들기\n",
        "!pip install -q grobid-client langchain openai faiss-cpu PyPDF2 tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API Key\n",
        "import openai\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "57LJbuG6boSh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#원하는 pdf파일 가져오기\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "reader = PdfReader(\"2311.13373.pdf\")\n",
        "raw_text = \"\"\n",
        "\n",
        "for i, page in enumerate(reader.pages):\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        raw_text += text\n",
        "\n",
        "print(raw_text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "76L4PnKrboWp",
        "outputId": "5e855159-1c4e-416f-ff37-2947d1a169bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16f09aa6-94ee-4d46-9a7c-1514e8eff2e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-16f09aa6-94ee-4d46-9a7c-1514e8eff2e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2311.13373.pdf to 2311.13373.pdf\n",
            "Large Language Model is a Good Policy Teacher for Training\n",
            "Reinforcement Learning Agents\n",
            "Zihao Zhou1,∗,Bin Hu1,∗,Pu Zhang1,Chenyang Zhao1and Bin Liu1,†\n",
            "1Research Center for Applied Mathematics and Machine Intelligence, Zhejiang Lab\n",
            "{zhouzihao,hubin,puz,c.zhao,liubin }@zhejianglab.com\n",
            "Abstract\n",
            "Recent studies have shown that Large Language\n",
            "Models (LLMs) can be utilized for solving com-\n",
            "plex sequential decision-making tasks by provid-\n",
            "ing high-level instructions. However, LLM-based\n",
            "agents face limitations in real-time dynamic envi-\n",
            "ronments due to their lack of specialization in solv-\n",
            "ing specific target problems. Moreover, the deploy-\n",
            "ment of such LLM-based agents is both costly and\n",
            "time-consuming in practical scenarios. In this pa-\n",
            "per, we introduce a novel framework that addresses\n",
            "these challenges by training a smaller scale spe-\n",
            "cialized student agent using instructions from an\n",
            "LLM-based teacher agent. By leveraging guided\n",
            "actions provided by the teachers, the prior knowl-\n",
            "edge of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize 요약\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import AnalyzeDocumentChain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)"
      ],
      "metadata": {
        "id": "sblT8yecboYy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_document_chain.run(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "5U8mLV2Eboa3",
        "outputId": "cd205a52-838d-4f2a-857e-8d9e998b3df5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This paper proposes a novel approach called LLM4Teach which leverages the knowledge embedded within Large Language Models (LLMs) to expedite the training process of a specialized small-scale student agent for a target task. Experiments on three challenging MiniGrid environments demonstrate that this approach enhances sample efficiency and achieves superior performance compared to baseline methods. The student agent is trained to optimize two objectives concurrently, maximizing the expected return and following a traditional RL algorithm. The teacher agent provides uncertainty-aware soft instructions to the student agent, and the student agent is able to rectify the mistakes made by the teacher, resulting in improved performance outcomes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 답변\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\") # gpt-3.5-turbo, gpt-4\n",
        "\n",
        "qa_chain = load_qa_chain(model, chain_type=\"map_reduce\")\n",
        "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)"
      ],
      "metadata": {
        "id": "KG1h_oktboc0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6분정도 소요 (0.3$)\n",
        "qa_document_chain.run(\n",
        "    input_document=raw_text,\n",
        "    question=\"llm이 어떻게 reinforcement에 도움이 된다는거야?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "VkkHyzqFboe6",
        "outputId": "09c1c2d0-c587-4d09-a68e-5f4827bea2fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LLM은 reinforcement learning 에이전트의 학습을 가속화하고 개선하는 데 도움이 될 수 있습니다. 이를 위해 LLM은 다음과 같은 방식으로 reinforcement learning 에이전트를 지원합니다:\\n\\n1. 지시 제공: LLM은 초기 탐색 단계를 가속화하기 위해 RL 에이전트에게 지시를 제공합니다. 학습을 시작할 때 LLM은 선생님 역할을 하며, RL 에이전트에게 필요한 행동에 대한 지시를 제공합니다.\\n\\n2. 피드백 제공: LLM은 환경과 상호작용하고 RL 에이전트에게 피드백을 제공하여 학습을 돕습니다. 이렇게 함으로써 RL 에이전트는 LLM의 지시에 따라 행동을 수정하고 성능을 향상시킬 수 있습니다.\\n\\n3. 탐사 효율성: LLM은 RL 에이전트의 탐사 효율성을 향상시킵니다. LLM은 선생님 역할을 수행하며, RL 에이전트가 환경에서 피드백을 받으면서 더 많은 샘플을 수집하고 더 효율적으로 탐사할 수 있도록 돕습니다.\\n\\n4. 정책 교사: LLM은 RL 에이전트의 정책 교사로 사용될 수 있습니다. LLM은 학습 단계에서 RL 에이전트에게 가이드를 제공하고, 실수를 교정하고 보상을 최적화하는 방향으로 학습할 수 있도록 돕습니다. 이를 통해 RL 에이전트는 보다 효율적으로 학습할 수 있습니다.\\n\\n이러한 방식으로 LLM은 reinforcement learning 에이전트의 학습 과정을 최적화하고 효율성을 향상시킬 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12분정도 소요 (0.02$)\n",
        "qa_document_chain.run(\n",
        "    input_document=raw_text,\n",
        "    question=\"위 내용을 가능하도록 하는 수학적인 원리가 뭔지 설명해줄수 있어??\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "GAxnZsK8bonX",
        "outputId": "16fc1288-5117-4460-cabb-1350b4d8a69b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'위 문서에서 언급된 수학적인 원리는 명시적으로 언급되지 않았지만, 강화학습과 정책 증류라는 관련된 수학적인 원리가 사용될 수 있습니다.\\n\\n강화학습은 순차적인 의사결정 문제를 다루는 머신러닝의 한 분야로, 에이전트가 환경과 상호작용하며 보상을 최대화하는 의사결정을 학습하는 것을 목표로 합니다. 강화학습에서 사용되는 주요한 수학적인 원리는 마르코프 결정 과정 (Markov Decision Process, MDP)와 벨만 방정식 (Bellman Equation)입니다.\\n\\n마르코프 결정 과정은 시간에 따라 변화하는 상태와 행동의 시퀀스를 모델링하는 프레임워크입니다. 상태 전이 확률과 보상 함수를 기반으로 최적의 의사결정을 추론하는 것이 목표입니다.\\n\\n벨만 방정식은 MDP에서 최적의 가치 함수를 계산하기 위해 사용되는 재귀적인 방정식입니다. 가치 함수는 특정 상태에서 시작하여 최적의 행동을 선택하고 미래의 보상을 최대화하는 가치를 나타냅니다.\\n\\n정책 증류는 강화학습에서 사용되는 기법 중 하나로, 미리 학습된 정책을 다른 에이전트에게 전달하는 방법입니다. 이를 통해 미리 학습된 정책의 지식을 더 경험적인 방법으로 학습하는 에이전트에게 전달할 수 있습니다.\\n\\n위 문서에서는 LLM 기반 에이전트의 학습 능력과 성능에 대해 언급하고 있으며, LLM을 통해 얻은 지식을 활용하여 에이전트의 행동을 개선하고 문제를 해결하는 방법을 제시하고 있습니다.\\n\\n하지만 위 문서에서 정확한 수학적인 원리에 대한 자세한 설명은 제공되지 않았으므로, 더 구체적인 수학적인 원리에 대한 이해를 위해서는 참고문헌을 확인하는 것이 좋습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}