{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9edbda4",
   "metadata": {},
   "source": [
    "# LSTM+normalization (내 생각과 더해서 하니 수익률 매우높아졌다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e07f8e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터: [134, 483, 47, 17, 153, 21, 213, 19, 146, 46, 60, 223, 294, 66, 47, 133, 19, 30, 18, 67, 227, 187, 154, 168, 33, 498, 165, 276, 171, 38, 137, 128, 35, 73, 132, 101, 34, 16, 65, 178, 10, 35, 310, 12, 93, 34, 100, 282, 170, 103, 197, 24, 121, 9, 3, 48, 257, 146, 116, 194, 157, 86, 209, 246, 240, 107, 57, 122, 13, 68, 178, 198, 107, 25, 354, 216, 7, 300, 50, 128, 182, 271, 173, 86, 12, 197, 210, 61, 270, 3, 180, 173, 98, 66, 112, 55, 8, 40, 109, 15, 164, 142, 171, 97, 371, 63, 73, 17, 458, 176, 422, 107, 33, 170, 43, 192, 93, 18, 294, 137, 30, 133, 42, 171, 155, 51, 90, 319, 39, 476, 191, 37, 36, 320, 77, 146, 1, 2, 10, 264, 145, 226, 42, 3, 41, 69, 71, 14, 268, 43, 453, 448, 59, 100, 310, 77, 29, 5, 3, 81, 179, 11, 72, 18, 139, 120, 85, 69, 96, 19, 132, 160, 143, 1, 278, 25, 167, 101, 90, 5, 104, 255, 297, 996, 6, 42, 16, 260, 19, 121, 72, 56, 29, 335, 118, 688, 15, 357, 246, 246, 85, 11, 306, 5, 5, 19, 20, 64, 61, 3, 136, 32, 21, 109, 15, 225, 4, 26, 53, 75, 156, 1, 11, 208, 88, 327, 6, 204, 73, 35, 59, 8, 9, 129, 40, 76, 54, 86, 276, 121, 62, 112, 99, 37, 13, 3, 32, 22, 39, 41, 293, 325, 16, 209, 136, 77, 30, 159, 11, 84, 132, 15, 326, 61, 68, 366, 81, 179, 240, 27, 52, 269, 125, 27, 15, 78, 27, 43, 7, 38, 20, 94, 323, 337, 140, 42, 207, 217, 58, 80, 97, 57, 18, 264, 133, 86, 85, 28, 106, 306, 48, 6, 11, 187, 62, 32, 256, 73, 262, 349, 86, 100, 81, 143, 323, 62, 79, 75, 50, 346, 281, 42, 80, 68, 13, 27, 276, 310, 38, 197, 1046, 230, 15, 39, 413, 52, 77, 80, 131, 34, 139, 89, 158, 236, 40, 105, 67, 8, 362, 404, 56, 245, 84, 53, 95, 149, 194, 152, 35, 26, 23, 138, 87, 3, 267, 168, 20, 54, 283, 59, 96, 407, 270, 122, 93, 71, 140, 90, 60, 241, 38, 11, 212, 25, 4, 108, 38, 103, 231, 12, 16, 187, 178, 94, 202, 33, 345, 161, 75, 23, 24, 45, 106, 28, 43, 194, 128, 49, 76, 83, 39, 48, 148, 187, 99, 18, 296, 127, 7, 222, 192, 45, 21, 56, 111, 260, 405, 32, 43, 104, 182, 273, 34, 64, 26, 226, 339, 145, 31, 9, 19, 50, 80, 95, 25, 215, 113, 130, 42, 12, 199, 166, 30, 456, 59, 38, 512, 87, 306, 410, 118, 23, 91, 19, 475, 47, 450, 146, 51, 272, 16, 2, 63, 223, 164, 230, 388, 112, 29, 35, 221, 288, 27, 121, 64, 24, 112, 3, 378, 560, 143, 21, 42, 123, 7, 185, 46, 236, 281, 32, 242, 318, 104, 15, 68, 135, 198, 262, 48, 148, 91, 30, 27, 35, 73, 13, 153, 236, 20, 100, 361, 276, 38, 190, 90, 14, 10, 308, 7, 25, 51, 196, 192, 85, 5, 60, 119, 22, 54, 52, 49, 653, 83, 200, 342, 9, 40, 131, 59, 41, 88, 168, 11, 170, 69, 60, 223, 29, 13, 73, 81, 283, 148, 14, 26, 5, 267, 289, 159, 89, 166, 431, 15, 220, 51, 205, 16, 7, 20, 71, 52, 75, 52, 9, 102, 40, 36, 226, 43, 60, 49, 24, 227, 250, 55, 82, 87, 104, 92, 268, 34, 25, 214, 135, 333, 149, 155, 166, 43, 132, 4, 51, 233, 119, 69, 44, 79, 24, 108, 86, 92, 158, 178, 102, 119, 158, 362, 209, 87, 43, 40, 14, 110, 89, 118, 31, 13, 91, 421, 96, 212, 79, 44, 17, 33, 172, 200, 121, 94, 59, 16, 98, 92, 226, 288, 35, 82, 415, 339, 32, 52, 235, 106, 384, 141, 12, 40, 49, 43, 29, 69, 33, 13, 217, 114, 168, 67, 142, 34, 23, 49, 73, 16, 52, 247, 3, 4, 200, 58, 18, 497, 141, 59, 551, 214, 174, 56, 195, 59, 49, 97, 3, 116, 51, 83, 15, 207, 16, 426, 74, 35, 147, 13, 84, 45, 21, 389, 56, 174, 28, 40, 106, 80, 150, 179, 159, 101, 139, 109, 71, 230, 1, 393, 21, 147, 51, 141, 112, 28, 124, 148, 138, 134, 29, 219, 453, 411, 27, 81, 22, 76, 58, 89, 85, 37, 17, 29, 48, 113, 45, 21, 474, 633, 32, 38, 77, 38, 45, 185, 522, 158, 130, 49, 150, 366, 41, 13, 242, 55, 144, 37, 263, 100, 422, 286, 193, 10, 89, 94, 310, 87, 60, 54, 33, 59, 198, 244, 38, 9, 22, 188, 33, 78, 295, 10, 312, 149, 30, 82, 255, 117, 36, 9, 93, 2, 237, 248, 60, 103, 73, 133, 3, 20, 218, 120, 63, 205, 4, 41, 25, 53, 61, 85, 363, 23, 29, 9, 208, 13, 157, 12, 104, 164, 37, 120, 200, 16, 379, 142, 52, 79, 186, 259, 135, 447, 14, 110, 2, 296, 422, 267, 42, 133, 50, 91, 15, 220, 246, 247, 56, 200, 39, 68, 89, 58, 133, 16, 24, 201, 63, 212, 550, 7, 64, 341, 54, 32, 469, 10, 27, 56, 58, 123, 25, 66, 44, 15, 147, 223, 55, 230, 190, 376, 171, 171, 4, 158, 28, 189, 342, 46, 140, 90, 8, 20, 78, 199, 82, 161, 98, 289, 84, 107, 8, 102, 2, 154, 176, 43, 231, 41, 924, 36, 179, 235, 206, 1, 115, 16, 38, 93, 359, 516, 5, 11, 35, 18, 68, 81, 152, 794, 44, 489, 285, 189, 118, 303, 86, 266, 250, 27, 12, 290, 31, 236, 77, 9, 6, 370, 131, 60, 330, 234, 92, 52, 465, 18, 78, 26, 239, 130, 124, 235, 152, 443, 57, 24, 45, 161, 157, 217, 264, 272, 7, 152, 24, 115, 169, 228, 151]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def generate_data(num_trials):\n",
    "    trials = []\n",
    "    for _ in range(num_trials):\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            if random.randint(1, 125) == 1:\n",
    "                break\n",
    "        trials.append(count)\n",
    "    return trials\n",
    "\n",
    "x_data = generate_data(1000)\n",
    "\n",
    "def apply_formula(x):\n",
    "    y = round(1-math.exp(-x/125),4)\n",
    "    return y\n",
    "\n",
    "def generate_y_list(x_list):\n",
    "    y_list = []\n",
    "    for x in x_list:\n",
    "        y = apply_formula(x)\n",
    "        y_list.append(y)\n",
    "    return y_list\n",
    "\n",
    "# Y 데이터 리스트 생성\n",
    "y_data = generate_y_list(x_data)\n",
    "\n",
    "print(\"X 데이터:\", x_data)\n",
    "#print(\"Y 데이터:\", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "772cbc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization_x_data = [6, 1, 1, 2, 6, 1, 1, 1, 3, 1, 1, 3, 3, 4, 3, 2, 2, 1, 4, 4, 6, 3, 5, 1, 1, 6, 6, 2, 2, 1, 6, 2, 2, 5, 2, 6, 1, 1, 6, 1, 1, 2, 2, 3, 1, 2, 4, 6, 4, 6, 1, 4, 1, 6, 2, 6, 4, 5, 1, 3, 2, 1, 1, 3, 6, 6, 2, 6, 1, 4, 1, 2, 6, 4, 2, 5, 1, 1, 1, 2, 6, 5, 5, 1, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 6, 1, 6, 1, 3, 3, 4, 1, 1, 3, 2, 6, 3, 4, 3, 4, 2, 1, 5, 4, 6, 1, 2, 1, 5, 1, 1, 6, 4, 1, 1, 1, 3, 1, 3, 1, 1, 4, 2, 3, 6, 1, 6, 4, 1, 1, 1, 3, 1, 3, 3, 1, 6, 4, 3, 1, 2, 1, 3, 3, 1, 1, 2, 1, 6, 3, 2, 6, 5, 5, 3, 2, 3, 2, 1, 6, 1, 2, 4, 4, 2, 1, 5, 1, 3, 5, 2, 1, 6, 4, 1, 5, 1, 4, 6, 3, 1, 6, 5, 2, 2, 5, 1, 1, 6, 6, 2, 4, 1, 2, 2, 2, 1, 5, 6, 6, 1, 2, 5, 6, 3, 3, 1, 2, 6, 6, 6, 3, 4, 3, 1, 1, 1, 1, 4, 1, 1, 5, 2, 2, 1, 2, 2, 2, 1, 6, 4, 2, 3, 4, 1, 2, 3, 6, 3, 3, 4, 6, 6, 3, 6, 3, 2, 3, 1, 2, 1, 4, 1, 2, 6, 4, 1, 1, 2, 2, 1, 2, 3, 1, 1, 3, 2, 3, 1, 2, 5, 2, 2, 3, 2, 2, 4, 6, 1, 1, 3, 2, 1, 1, 2, 1, 1, 3, 1, 3, 6, 2, 2, 1, 1, 1, 1, 3, 1, 6, 6, 6, 5, 1, 2, 3, 2, 2, 4, 6, 1, 1, 1, 2, 2, 6, 3, 1, 3, 2, 4, 2, 6, 1, 1, 6, 6, 2, 3, 3, 2, 1, 1, 3, 1, 1, 6, 1, 3, 3, 3, 2, 4, 3, 2, 4, 1, 1, 2, 3, 2, 2, 1, 1, 3, 3, 4, 5, 1, 6, 1, 6, 4, 3, 1, 3, 6, 5, 2, 1, 2, 3, 3, 2, 4, 2, 1, 2, 3, 2, 2, 3, 4, 1, 1, 2, 1, 2, 4, 2, 1, 5, 3, 1, 2, 3, 2, 6, 4, 1, 2, 2, 6, 1, 5, 3, 3, 4, 1, 3, 2, 4, 5, 1, 4, 3, 4, 3, 1, 1, 4, 3, 1, 4, 2, 2, 2, 1, 1, 3, 4, 1, 4, 2, 6, 3, 2, 3, 1, 6, 1, 2, 6, 1, 1, 4, 1, 2, 2, 1, 5, 1, 6, 5, 6, 2, 2, 6, 1, 1, 3, 2, 4, 2, 3, 2, 2, 2, 3, 2, 6, 5, 1, 2, 2, 6, 2, 1, 2, 2, 1, 1, 6, 1, 3, 4, 6, 5, 1, 5, 3, 1, 4, 3, 4, 1, 3, 2, 1, 1, 3, 5, 3, 3, 6, 1, 3, 4, 4, 3, 3, 4, 2, 2, 4, 2, 2, 2, 1, 1, 6, 1, 1, 5, 1, 3, 1, 4, 1, 3, 5, 6, 6, 1, 6, 6, 1, 5, 1, 6, 6, 3, 1, 6, 3, 2, 2, 3, 6, 6, 4, 2, 1, 1, 2, 6, 1, 2, 6, 4, 6, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 6, 4, 6, 1, 1, 6, 1, 4, 3, 1, 5, 2, 3, 4, 1, 1, 4, 1, 6, 6, 2, 1, 6, 1, 1, 1, 4, 3, 1, 4, 6, 1, 2, 1, 1, 4, 2, 4, 4, 6, 6, 1, 2, 3, 2, 3, 1, 4, 2, 6, 4, 2, 2, 1, 3, 1, 6, 2, 2, 5, 6, 4, 2, 6, 1, 3, 3, 2, 5, 1, 2, 1, 3, 1, 2, 4, 4, 1, 1, 1, 1, 5, 4, 1, 3, 4, 4, 1, 1, 2, 6, 2, 3, 2, 1, 1, 4, 2, 3, 4, 1, 2, 6, 4, 1, 1, 6, 1, 1, 2, 6, 1, 6, 1, 2, 1, 4, 3, 2, 1, 4, 2, 1, 1, 5, 1, 2, 1, 3, 2, 6, 2, 6, 3, 2, 1, 6, 3, 4, 1, 6, 4, 1, 2, 1, 1, 3, 6, 6, 5, 2, 1, 3, 3, 2, 2, 5, 1, 2, 2, 1, 1, 1, 1, 3, 6, 5, 1, 5, 1, 3, 3, 3, 5, 1, 2, 5, 1, 2, 2, 6, 2, 6, 2, 1, 1, 3, 2, 2, 5, 1, 6, 3, 3, 4, 2, 3, 3, 2, 1, 1, 3, 1, 6, 1, 1, 6, 1, 1, 5, 6, 2, 6, 6, 5, 1, 3, 2, 6, 6, 1, 1, 6, 1, 2, 2, 1, 4, 5, 4, 5, 6, 2, 1, 3, 1, 5, 1, 2, 3, 2, 3, 2, 2, 1, 6, 1, 1, 2, 1, 6, 4, 4, 2, 6, 5, 2, 1, 3, 6, 2, 4, 2, 1, 2, 1, 1, 6, 1, 1, 1, 2, 6, 2, 6, 3, 2, 6, 3, 3, 6, 4, 4, 1, 1, 5, 1, 4, 3, 2, 1, 1, 4, 5, 1, 2, 2, 4, 1, 1, 6, 1, 1, 3, 2, 5, 2, 4, 5, 1, 2, 5, 3, 2, 3, 2, 1, 6, 1, 6, 1, 4, 2, 3, 1, 6, 2, 1, 5, 1, 1, 2, 1, 1, 2, 1, 4, 4, 3, 6, 3, 2, 1, 1, 1, 1, 4, 4, 1, 1, 4, 2, 6, 2, 1, 6, 2, 4, 2, 2, 2, 3, 6, 2, 6, 2, 3, 3, 4, 1, 1, 4, 1, 3, 1, 6, 6, 4, 6, 2, 1, 2, 1, 2, 6, 3, 1, 1, 2, 1, 3, 6, 3, 3, 4, 2, 4, 3, 1, 3, 1, 3, 3, 6, 2, 3, 3, 3, 2, 1, 2, 2, 6, 4, 1, 1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "def assign_numbers_based_on_range(numbers, ranges):\n",
    "    new_list = []\n",
    "    for number in numbers:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "# 사용 예시\n",
    "numbers = x_data\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_data = assign_numbers_based_on_range(numbers, ranges)\n",
    "print(\"normalization_x_data =\", normalization_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "84dae5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1 1]\n",
      " [1 1 2]\n",
      " [1 2 6]\n",
      " ...\n",
      " [6 4 1]\n",
      " [4 1 1]\n",
      " [1 1 4]]\n",
      "[2 6 1 1 1 3 1 1 3 3 4 3 2 2 1 4 4 6 3 5 1 1 6 6 2 2 1 6 2 2 5 2 6 1 1 6 1\n",
      " 1 2 2 3 1 2 4 6 4 6 1 4 1 6 2 6 4 5 1 3 2 1 1 3 6 6 2 6 1 4 1 2 6 4 2 5 1\n",
      " 1 1 2 6 5 5 1 2 2 1 2 2 3 1 1 1 1 6 1 6 1 3 3 4 1 1 3 2 6 3 4 3 4 2 1 5 4\n",
      " 6 1 2 1 5 1 1 6 4 1 1 1 3 1 3 1 1 4 2 3 6 1 6 4 1 1 1 3 1 3 3 1 6 4 3 1 2\n",
      " 1 3 3 1 1 2 1 6 3 2 6 5 5 3 2 3 2 1 6 1 2 4 4 2 1 5 1 3 5 2 1 6 4 1 5 1 4\n",
      " 6 3 1 6 5 2 2 5 1 1 6 6 2 4 1 2 2 2 1 5 6 6 1 2 5 6 3 3 1 2 6 6 6 3 4 3 1\n",
      " 1 1 1 4 1 1 5 2 2 1 2 2 2 1 6 4 2 3 4 1 2 3 6 3 3 4 6 6 3 6 3 2 3 1 2 1 4\n",
      " 1 2 6 4 1 1 2 2 1 2 3 1 1 3 2 3 1 2 5 2 2 3 2 2 4 6 1 1 3 2 1 1 2 1 1 3 1\n",
      " 3 6 2 2 1 1 1 1 3 1 6 6 6 5 1 2 3 2 2 4 6 1 1 1 2 2 6 3 1 3 2 4 2 6 1 1 6\n",
      " 6 2 3 3 2 1 1 3 1 1 6 1 3 3 3 2 4 3 2 4 1 1 2 3 2 2 1 1 3 3 4 5 1 6 1 6 4\n",
      " 3 1 3 6 5 2 1 2 3 3 2 4 2 1 2 3 2 2 3 4 1 1 2 1 2 4 2 1 5 3 1 2 3 2 6 4 1\n",
      " 2 2 6 1 5 3 3 4 1 3 2 4 5 1 4 3 4 3 1 1 4 3 1 4 2 2 2 1 1 3 4 1 4 2 6 3 2\n",
      " 3 1 6 1 2 6 1 1 4 1 2 2 1 5 1 6 5 6 2 2 6 1 1 3 2 4 2 3 2 2 2 3 2 6 5 1 2\n",
      " 2 6 2 1 2 2 1 1 6 1 3 4 6 5 1 5 3 1 4 3 4 1 3 2 1 1 3 5 3 3 6 1 3 4 4 3 3\n",
      " 4 2 2 4 2 2 2 1 1 6 1 1 5 1 3 1 4 1 3 5 6 6 1 6 6 1 5 1 6 6 3 1 6 3 2 2 3\n",
      " 6 6 4 2 1 1 2 6 1 2 6 4 6 2 1 1 1 1 1 3 3 1 1 1 6 4 6 1 1 6 1 4 3 1 5 2 3\n",
      " 4 1 1 4 1 6 6 2 1 6 1 1 1 4 3 1 4 6 1 2 1 1 4 2 4 4 6 6 1 2 3 2 3 1 4 2 6\n",
      " 4 2 2 1 3 1 6 2 2 5 6 4 2 6 1 3 3 2 5 1 2 1 3 1 2 4 4 1 1 1 1 5 4 1 3 4 4\n",
      " 1 1 2 6 2 3 2 1 1 4 2 3 4 1 2 6 4 1 1 6 1 1 2 6 1 6 1 2 1 4 3 2 1 4 2 1 1\n",
      " 5 1 2 1 3 2 6 2 6 3 2 1 6 3 4 1 6 4 1 2 1 1 3 6 6 5 2 1 3 3 2 2 5 1 2 2 1\n",
      " 1 1 1 3 6 5 1 5 1 3 3 3 5 1 2 5 1 2 2 6 2 6 2 1 1 3 2 2 5 1 6 3 3 4 2 3 3\n",
      " 2 1 1 3 1 6 1 1 6 1 1 5 6 2 6 6 5 1 3 2 6 6 1 1 6 1 2 2 1 4 5 4 5 6 2 1 3\n",
      " 1 5 1 2 3 2 3 2 2 1 6 1 1 2 1 6 4 4 2 6 5 2 1 3 6 2 4 2 1 2 1 1 6 1 1 1 2\n",
      " 6 2 6 3 2 6 3 3 6 4 4 1 1 5 1 4 3 2 1 1 4 5 1 2 2 4 1 1 6 1 1 3 2 5 2 4 5\n",
      " 1 2 5 3 2 3 2 1 6 1 6 1 4 2 3 1 6 2 1 5 1 1 2 1 1 2 1 4 4 3 6 3 2 1 1 1 1\n",
      " 4 4 1 1 4 2 6 2 1 6 2 4 2 2 2 3 6 2 6 2 3 3 4 1 1 4 1 3 1 6 6 4 6 2 1 2 1\n",
      " 2 6 3 1 1 2 1 3 6 3 3 4 2 4 3 1 3 1 3 3 6 2 3 3 3 2 1 2 2 6 4 1 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(numbers, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(numbers)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(numbers)-1:\n",
    "            break\n",
    "        seq_x, seq_y = numbers[i:end_ix], numbers[end_ix] # end_ix는 포함되지 않는다.\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 숫자 시퀀스 정의\n",
    "numbers = normalization_x_data\n",
    "n_steps = 3 # 학습하고싶은 숫자묶음의 크기(발걸음)을 설정합니다. #패딩이용해서 자율적으로 컨드롤할수있도록\n",
    "\n",
    "# 데이터셋 생성\n",
    "X, y = create_dataset(numbers, n_steps) #데이터셋 생성 함수 활성화\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7594b68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/32 [..............................] - ETA: 15s - loss: 9.8987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 7.9666\n",
      "Epoch 2/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 5.3035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.7876\n",
      "Epoch 3/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3812WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.2707\n",
      "Epoch 4/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.8313WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.0230\n",
      "Epoch 5/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.3863WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.8422\n",
      "Epoch 6/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.7586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.6959\n",
      "Epoch 7/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.8552WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.6235\n",
      "Epoch 8/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.1399WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.4342\n",
      "Epoch 9/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.4273WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.3281\n",
      "Epoch 10/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 5.1471WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.2628\n",
      "Epoch 11/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 1.9226WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1948\n",
      "Epoch 12/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.2701WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.2004\n",
      "Epoch 13/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4061WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1375\n",
      "Epoch 14/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.7347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1197\n",
      "Epoch 15/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9857WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1299\n",
      "Epoch 16/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.6039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1059\n",
      "Epoch 17/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1142\n",
      "Epoch 18/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9994WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1095\n",
      "Epoch 19/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0746WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1029\n",
      "Epoch 20/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0527WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0979\n",
      "Epoch 21/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.7973WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1303\n",
      "Epoch 22/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 1.9252WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0989\n",
      "Epoch 23/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.6011WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1189\n",
      "Epoch 24/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.6757WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1146\n",
      "Epoch 25/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9686WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1061\n",
      "Epoch 26/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.8285WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1098\n",
      "Epoch 27/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.8528WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0911\n",
      "Epoch 28/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5738WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1004\n",
      "Epoch 29/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3301WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1042\n",
      "Epoch 30/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.1595WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1109\n",
      "Epoch 31/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.6050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1317\n",
      "Epoch 32/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.1048WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0994\n",
      "Epoch 33/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.7065WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0966\n",
      "Epoch 34/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.4995WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0963\n",
      "Epoch 35/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.8848WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0927\n",
      "Epoch 36/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.8459WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0996\n",
      "Epoch 37/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3084WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0904\n",
      "Epoch 38/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.1026WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0909\n",
      "Epoch 39/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.9950WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1088\n",
      "Epoch 40/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.5407WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1036\n",
      "Epoch 41/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0132WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0902\n",
      "Epoch 42/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 1.8889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0937\n",
      "Epoch 43/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.0465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0920\n",
      "Epoch 44/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5809WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0892\n",
      "Epoch 45/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.2538WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0835\n",
      "Epoch 46/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4210WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0902\n",
      "Epoch 47/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.4409WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0841\n",
      "Epoch 48/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.8347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1013\n",
      "Epoch 49/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.3029WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0878\n",
      "Epoch 50/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.4895WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1192\n",
      "Epoch 51/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2231WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0919\n",
      "Epoch 52/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.5340WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0886\n",
      "Epoch 53/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9743WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0866\n",
      "Epoch 54/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3136WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0856\n",
      "Epoch 55/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.3128WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0855\n",
      "Epoch 56/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3792WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0929\n",
      "Epoch 57/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.3487WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0841\n",
      "Epoch 58/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.5829WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0874\n",
      "Epoch 59/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5247WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0881\n",
      "Epoch 60/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.1251WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0975\n",
      "Epoch 61/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9059WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0963\n",
      "Epoch 62/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9154WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0872\n",
      "Epoch 63/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.0801WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0898\n",
      "Epoch 64/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.7551WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0655\n",
      "Epoch 65/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.1940WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0974\n",
      "Epoch 66/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.1893WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1045\n",
      "Epoch 67/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0986WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0855\n",
      "Epoch 68/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5274WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0808\n",
      "Epoch 69/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9354WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1009\n",
      "Epoch 70/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.8225WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0855\n",
      "Epoch 71/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.2682WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0826\n",
      "Epoch 72/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.8858WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0877\n",
      "Epoch 73/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.9918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0890\n",
      "Epoch 74/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4572WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0927\n",
      "Epoch 75/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.6202WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.1109\n",
      "Epoch 76/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4432WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0775\n",
      "Epoch 77/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9717WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0828\n",
      "Epoch 78/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0012WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0856\n",
      "Epoch 79/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.7379WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0886\n",
      "Epoch 80/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2084WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0785\n",
      "Epoch 81/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.6779WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0755\n",
      "Epoch 82/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.1909WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0781\n",
      "Epoch 83/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.8472WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0803\n",
      "Epoch 84/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.4632WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0742\n",
      "Epoch 85/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4604WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0857\n",
      "Epoch 86/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.7460WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0850\n",
      "Epoch 87/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5309WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0847\n",
      "Epoch 88/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2066WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0857\n",
      "Epoch 89/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.2423WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0768\n",
      "Epoch 90/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.1824WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0718\n",
      "Epoch 91/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 1.9767WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0840\n",
      "Epoch 92/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.2188WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0795\n",
      "Epoch 93/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.6660WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0960\n",
      "Epoch 94/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.4702WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0972\n",
      "Epoch 95/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2505WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0847\n",
      "Epoch 96/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 3.0308WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0732\n",
      "Epoch 97/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 4.1634WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0875\n",
      "Epoch 98/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.9153WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0745\n",
      "Epoch 99/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.2608WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0769\n",
      "Epoch 100/100\n",
      " 1/32 [..............................] - ETA: 0s - loss: 2.5984WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.0866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c4373220>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM 모델 정의\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, 1))) # 50은 층에있는 뉴런의 수\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 훈련을 위해 X를 재구성\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 조기 종료 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련 (내가 생각했을떄 이것은 같은 상황의 반복이므로 에포크를 높게할수록 잘적중될것이다. 그러나 학습하더라도 램덤떄문에 성능개선에 한계가 있다)\n",
    "model.fit(X, y, epochs=100, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# ETA는 0인데 loss는 계속 내려가면 진정한 학습은 안일어나는데 데이터셋에대해서는 학습이 일어나고 있다는건가?\n",
    "# 그것이아니라 ETA가 0인것은 매우짧은 시간안에 학습된다는 시간의 의미였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "95ced5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization_x_data = [6, 1, 1, 2, 6, 1, 1, 1, 3, 1, 1, 3, 3, 4, 3, 2, 2, 1, 4, 4, 6, 3, 5, 1, 1, 6, 6, 2, 2, 1, 6, 2, 2, 5, 2, 6, 1, 1, 6, 1, 1, 2, 2, 3, 1, 2, 4, 6, 4, 6, 1, 4, 1, 6, 2, 6, 4, 5, 1, 3, 2, 1, 1, 3, 6, 6, 2, 6, 1, 4, 1, 2, 6, 4, 2, 5, 1, 1, 1, 2, 6, 5, 5, 1, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 6, 1, 6, 1, 3, 3, 4, 1, 1, 3, 2, 6, 3, 4, 3, 4, 2, 1, 5, 4, 6, 1, 2, 1, 5, 1, 1, 6, 4, 1, 1, 1, 3, 1, 3, 1, 1, 4, 2, 3, 6, 1, 6, 4, 1, 1, 1, 3, 1, 3, 3, 1, 6, 4, 3, 1, 2, 1, 3, 3, 1, 1, 2, 1, 6, 3, 2, 6, 5, 5, 3, 2, 3, 2, 1, 6, 1, 2, 4, 4, 2, 1, 5, 1, 3, 5, 2, 1, 6, 4, 1, 5, 1, 4, 6, 3, 1, 6, 5, 2, 2, 5, 1, 1, 6, 6, 2, 4, 1, 2, 2, 2, 1, 5, 6, 6, 1, 2, 5, 6, 3, 3, 1, 2, 6, 6, 6, 3, 4, 3, 1, 1, 1, 1, 4, 1, 1, 5, 2, 2, 1, 2, 2, 2, 1, 6, 4, 2, 3, 4, 1, 2, 3, 6, 3, 3, 4, 6, 6, 3, 6, 3, 2, 3, 1, 2, 1, 4, 1, 2, 6, 4, 1, 1, 2, 2, 1, 2, 3, 1, 1, 3, 2, 3, 1, 2, 5, 2, 2, 3, 2, 2, 4, 6, 1, 1, 3, 2, 1, 1, 2, 1, 1, 3, 1, 3, 6, 2, 2, 1, 1, 1, 1, 3, 1, 6, 6, 6, 5, 1, 2, 3, 2, 2, 4, 6, 1, 1, 1, 2, 2, 6, 3, 1, 3, 2, 4, 2, 6, 1, 1, 6, 6, 2, 3, 3, 2, 1, 1, 3, 1, 1, 6, 1, 3, 3, 3, 2, 4, 3, 2, 4, 1, 1, 2, 3, 2, 2, 1, 1, 3, 3, 4, 5, 1, 6, 1, 6, 4, 3, 1, 3, 6, 5, 2, 1, 2, 3, 3, 2, 4, 2, 1, 2, 3, 2, 2, 3, 4, 1, 1, 2, 1, 2, 4, 2, 1, 5, 3, 1, 2, 3, 2, 6, 4, 1, 2, 2, 6, 1, 5, 3, 3, 4, 1, 3, 2, 4, 5, 1, 4, 3, 4, 3, 1, 1, 4, 3, 1, 4, 2, 2, 2, 1, 1, 3, 4, 1, 4, 2, 6, 3, 2, 3, 1, 6, 1, 2, 6, 1, 1, 4, 1, 2, 2, 1, 5, 1, 6, 5, 6, 2, 2, 6, 1, 1, 3, 2, 4, 2, 3, 2, 2, 2, 3, 2, 6, 5, 1, 2, 2, 6, 2, 1, 2, 2, 1, 1, 6, 1, 3, 4, 6, 5, 1, 5, 3, 1, 4, 3, 4, 1, 3, 2, 1, 1, 3, 5, 3, 3, 6, 1, 3, 4, 4, 3, 3, 4, 2, 2, 4, 2, 2, 2, 1, 1, 6, 1, 1, 5, 1, 3, 1, 4, 1, 3, 5, 6, 6, 1, 6, 6, 1, 5, 1, 6, 6, 3, 1, 6, 3, 2, 2, 3, 6, 6, 4, 2, 1, 1, 2, 6, 1, 2, 6, 4, 6, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 6, 4, 6, 1, 1, 6, 1, 4, 3, 1, 5, 2, 3, 4, 1, 1, 4, 1, 6, 6, 2, 1, 6, 1, 1, 1, 4, 3, 1, 4, 6, 1, 2, 1, 1, 4, 2, 4, 4, 6, 6, 1, 2, 3, 2, 3, 1, 4, 2, 6, 4, 2, 2, 1, 3, 1, 6, 2, 2, 5, 6, 4, 2, 6, 1, 3, 3, 2, 5, 1, 2, 1, 3, 1, 2, 4, 4, 1, 1, 1, 1, 5, 4, 1, 3, 4, 4, 1, 1, 2, 6, 2, 3, 2, 1, 1, 4, 2, 3, 4, 1, 2, 6, 4, 1, 1, 6, 1, 1, 2, 6, 1, 6, 1, 2, 1, 4, 3, 2, 1, 4, 2, 1, 1, 5, 1, 2, 1, 3, 2, 6, 2, 6, 3, 2, 1, 6, 3, 4, 1, 6, 4, 1, 2, 1, 1, 3, 6, 6, 5, 2, 1, 3, 3, 2, 2, 5, 1, 2, 2, 1, 1, 1, 1, 3, 6, 5, 1, 5, 1, 3, 3, 3, 5, 1, 2, 5, 1, 2, 2, 6, 2, 6, 2, 1, 1, 3, 2, 2, 5, 1, 6, 3, 3, 4, 2, 3, 3, 2, 1, 1, 3, 1, 6, 1, 1, 6, 1, 1, 5, 6, 2, 6, 6, 5, 1, 3, 2, 6, 6, 1, 1, 6, 1, 2, 2, 1, 4, 5, 4, 5, 6, 2, 1, 3, 1, 5, 1, 2, 3, 2, 3, 2, 2, 1, 6, 1, 1, 2, 1, 6, 4, 4, 2, 6, 5, 2, 1, 3, 6, 2, 4, 2, 1, 2, 1, 1, 6, 1, 1, 1, 2, 6, 2, 6, 3, 2, 6, 3, 3, 6, 4, 4, 1, 1, 5, 1, 4, 3, 2, 1, 1, 4, 5, 1, 2, 2, 4, 1, 1, 6, 1, 1, 3, 2, 5, 2, 4, 5, 1, 2, 5, 3, 2, 3, 2, 1, 6, 1, 6, 1, 4, 2, 3, 1, 6, 2, 1, 5, 1, 1, 2, 1, 1, 2, 1, 4, 4, 3, 6, 3, 2, 1, 1, 1, 1, 4, 4, 1, 1, 4, 2, 6, 2, 1, 6, 2, 4, 2, 2, 2, 3, 6, 2, 6, 2, 3, 3, 4, 1, 1, 4, 1, 3, 1, 6, 6, 4, 6, 2, 1, 2, 1, 2, 6, 3, 1, 1, 2, 1, 3, 6, 3, 3, 4, 2, 4, 3, 1, 3, 1, 3, 3, 6, 2, 3, 3, 3, 2, 1, 2, 2, 6, 4, 1, 1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def assign_numbers_based_on_range(numbers, ranges):\n",
    "    new_list = []\n",
    "    for number in numbers:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "# 사용 예시\n",
    "numbers = [342, 123, 232] # 잘작동하나 실험을 학습한 데이터중 하나로하면 실전에서 잘 적용되는지 모르므로 밖에있는 새로운 데이터로 학습시켜보아야한다.\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_input = assign_numbers_based_on_range(numbers, ranges)\n",
    "print(\"normalization_x_data =\", normalization_x_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2180c74",
   "metadata": {},
   "source": [
    "# 위에까지가 모델 한덩이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9a8cf70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6275303"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이렇게 나눠놓으니 위에 학습한것을 토대로 계속 학습하면 시간 안걸리고 다음숫자 예측할수있다.\n",
    "\n",
    "# 예측을 위한 새로운 데이터 포인트\n",
    "x_input = np.array([5, 5, 5]) # 학습된 데이터에 대해서는 잘작동하게는 했었다.\n",
    "x_input = x_input.reshape((1, n_steps, 1))\n",
    "\n",
    "# 다음 숫자 예측\n",
    "yhat = model.predict(x_input, verbose=1) # verbose 설정에따라 학습상황을 아려줍니다.\n",
    "yhat[0][0]  # 예측된 다음 숫자 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfe01a",
   "metadata": {},
   "source": [
    "# 새로운 입력 normalization해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "500ea7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization_x_data = [1, 4, 3, 4, 2, 1, 1, 3, 3, 1, 3, 6, 4, 4, 4, 1, 2, 2, 5, 4, 4, 5, 3, 3, 4, 6, 3, 3, 2, 4, 2, 2, 1, 6, 6, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 4, 1, 3, 2, 1, 1, 2, 6, 1, 1, 3, 1, 5, 6, 4, 6, 1, 1, 1, 6, 1, 2, 1, 4, 4, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 2, 6, 3, 1, 2, 3, 1, 2, 2, 1, 3, 1, 1, 2, 1, 3, 1, 4, 1, 1, 6, 1, 3, 3, 6, 6, 2, 1, 2, 2, 1, 2, 6, 4, 2, 2, 1, 1, 2, 2, 2, 4, 5, 2, 3, 1, 6, 5, 6, 2, 5, 3, 2, 2, 1, 2, 4, 1, 1, 2, 1, 2, 1, 3, 1, 6, 6, 6, 1, 1, 2, 3, 6, 1, 4, 2, 1, 1, 2, 1, 1, 6, 1, 2, 1, 2, 1, 1, 2, 6, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 5, 2, 1, 2, 1, 1, 2, 1, 1, 6, 2, 1, 1, 4, 6, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def assign_numbers_based_on_range(numbers, ranges):\n",
    "    new_list = []\n",
    "    for number in numbers:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "# 사용 예시\n",
    "numbers = [79, 114, 5, 3, 169] # 잘작동하나 실험을 학습한 데이터중 하나로하면 실전에서 잘 적용되는지 모르므로 밖에있는 새로운 데이터로 학습시켜보아야한다.\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_input = assign_numbers_based_on_range(numbers, ranges)\n",
    "print(\"normalization_x_data =\", normalization_x_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "48ab4a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0480866"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_numbers_based_on_range(numbers, ranges):\n",
    "    new_list = []\n",
    "    for number in numbers:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "numbers = [381, 82, 42] # 잘작동하나 실험을 학습한 데이터중 하나로하면 실전에서 잘 적용되는지 모르므로 밖에있는 새로운 데이터로 학습시켜보아야한다.\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_input = assign_numbers_based_on_range(numbers, ranges)\n",
    "\n",
    "x_input = np.array([normalization_x_input]) # 학습된 데이터에 대해서는 잘작동하게는 했었다.\n",
    "x_input = x_input.reshape((1, n_steps, 1))\n",
    "\n",
    "# 다음 숫자 예측\n",
    "yhat = model.predict(x_input, verbose=1) # verbose 설정에따라 학습상황을 아려줍니다.\n",
    "yhat[0][0]  # 예측된 다음 숫자 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c78a189d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. o\\n2. x(램덤 변수라 틱장애 같은놈 있으므로 가끔틀릴수도있다.)\\n3. o\\n4. o\\n5. o\\n6. o(이정도면 모델 완성도 꽤높다 적중률 혼자 예측할떄보다 굉장히 높다.)\\n7. x\\n8. x\\n9.\\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 밖에서의 정답률 한번 보자(이것도 코드로 만들수있으나 내가 한번 직접해보고 코드만들자)\n",
    "# 정답률 재는거 코드로 만들어야 모델 바꿔가며 학습잘되었는지 빠르게 확인할수있다.\n",
    "'''\n",
    "1. o\n",
    "2. x(램덤 변수라 틱장애 같은놈 있으므로 가끔틀릴수도있다.)\n",
    "3. o\n",
    "4. o\n",
    "5. o\n",
    "6. o(이정도면 모델 완성도 꽤높다 적중률 혼자 예측할떄보다 굉장히 높다.)\n",
    "7. x\n",
    "8. x\n",
    "9.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5490e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
