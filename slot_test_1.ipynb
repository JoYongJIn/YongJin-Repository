{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e70ec857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터: [361, 130, 86, 157, 111, 90, 368, 54, 309, 195, 932, 156, 98, 203, 103, 12, 96, 143, 212, 8, 56, 8, 137, 1, 101, 171, 374, 62, 315, 408, 121, 247, 108, 150, 248, 67, 286, 19, 2, 268, 89, 49, 32, 69, 285, 29, 68, 49, 136, 63, 3, 16, 236, 520, 20, 66, 7, 70, 96, 162, 117, 92, 5, 53, 84, 159, 22, 47, 243, 18, 29, 40, 83, 173, 773, 28, 136, 6, 161, 516, 76, 105, 113, 90, 67, 1, 46, 69, 67, 14, 2, 18, 21, 349, 1160, 519, 51, 286, 129, 64, 30, 190, 22, 21, 49, 217, 282, 61, 18, 83, 263, 9, 1, 78, 65, 191, 33, 138, 6, 313, 21, 64, 105, 347, 87, 47, 148, 340, 27, 5, 123, 195, 16, 49, 12, 153, 47, 295, 36, 59, 6, 17, 15, 19, 2, 187, 66, 53, 70, 118, 12, 51, 183, 23, 105, 6, 27, 144, 154, 71, 206, 15, 9, 364, 180, 51, 49, 232, 59, 286, 61, 60, 41, 20, 405, 207, 84, 208, 435, 261, 37, 213, 81, 122, 17, 161, 294, 53, 94, 320, 147, 249, 54, 60, 42, 140, 207, 95, 30, 13, 4, 294, 2, 281, 43, 213, 195, 94, 267, 152, 80, 246, 160, 28, 59, 555, 8, 39, 245, 105, 1, 139, 35, 132, 28, 165, 89, 97, 233, 25, 11, 13, 4, 202, 126, 186, 239, 89, 22, 61, 50, 423, 71, 397, 181, 85, 47, 79, 29, 449, 104, 24, 305, 29, 26, 45, 56, 214, 30, 316, 103, 87, 6, 254, 73, 298, 343, 46, 28, 126, 120, 83, 91, 24, 64, 16, 150, 115, 38, 1, 36, 201, 90, 106, 18, 70, 3, 66, 113, 130, 58, 113, 50, 38, 7, 170, 311, 78, 96, 26]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def generate_data(num_trials):\n",
    "    trials = []\n",
    "    for _ in range(num_trials):\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            if random.randint(1, 125) == 1:\n",
    "                break\n",
    "        trials.append(count)\n",
    "    return trials\n",
    "\n",
    "x_data = generate_data(300)\n",
    "\n",
    "def apply_formula(x):\n",
    "    y = round(1-math.exp(-x/125),4)\n",
    "    return y\n",
    "\n",
    "def generate_y_list(x_list):\n",
    "    y_list = []\n",
    "    for x in x_list:\n",
    "        y = apply_formula(x)\n",
    "        y_list.append(y)\n",
    "    return y_list\n",
    "\n",
    "# Y 데이터 리스트 생성\n",
    "y_data = generate_y_list(x_data)\n",
    "\n",
    "print(\"X 데이터:\", x_data)\n",
    "#print(\"Y 데이터:\", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f54e41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization_x_data = [6, 3, 2, 4, 3, 2, 6, 2, 6, 4, 6, 4, 2, 5, 3, 1, 2, 3, 5, 1, 2, 1, 3, 1, 2, 4, 6, 2, 6, 6, 3, 5, 3, 3, 5, 2, 6, 1, 1, 6, 2, 1, 1, 2, 6, 1, 2, 1, 3, 2, 1, 1, 5, 6, 1, 2, 1, 2, 2, 4, 3, 2, 1, 2, 2, 4, 1, 1, 5, 1, 1, 1, 2, 4, 6, 1, 3, 1, 4, 6, 2, 3, 3, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 6, 6, 6, 1, 6, 3, 2, 1, 4, 1, 1, 1, 5, 6, 2, 1, 2, 6, 1, 1, 2, 2, 4, 1, 3, 1, 6, 1, 2, 3, 6, 2, 1, 3, 6, 1, 1, 3, 4, 1, 1, 1, 4, 1, 6, 1, 2, 1, 1, 1, 1, 1, 4, 2, 2, 2, 3, 1, 1, 4, 1, 3, 1, 1, 3, 4, 2, 5, 1, 1, 6, 4, 1, 1, 5, 2, 6, 2, 2, 1, 1, 6, 5, 2, 5, 6, 6, 1, 5, 2, 3, 1, 4, 6, 2, 2, 6, 3, 5, 2, 2, 1, 3, 5, 2, 1, 1, 1, 6, 1, 6, 1, 5, 4, 2, 6, 4, 2, 5, 4, 1, 2, 6, 1, 1, 5, 3, 1, 3, 1, 3, 1, 4, 2, 2, 5, 1, 1, 1, 1, 5, 3, 4, 5, 2, 1, 2, 1, 6, 2, 6, 4, 2, 1, 2, 1, 6, 3, 1, 6, 1, 1, 1, 2, 5, 1, 6, 3, 2, 1, 6, 2, 6, 6, 1, 1, 3, 3, 2, 2, 1, 2, 1, 3, 3, 1, 1, 1, 4, 2, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 1, 4, 6, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def assign_numbers_based_on_range(numbers, ranges):\n",
    "    new_list = []\n",
    "    for number in numbers:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "# 사용 예시\n",
    "numbers = x_data\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_data = assign_numbers_based_on_range(numbers, ranges)\n",
    "print(\"normalization_x_data =\", normalization_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5aa58a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6], [3, 2, 4, 3, 2, 6], [2, 6], [4, 6], [4, 2, 5, 3, 1, 2, 3, 5, 1, 2, 1, 3, 1, 2, 4, 6], [2, 6], [6], [3, 5, 3, 3, 5, 2, 6], [1, 1, 6], [2, 1, 1, 2, 6], [1, 2, 1, 3, 2, 1, 1, 5, 6], [1, 2, 1, 2, 2, 4, 3, 2, 1, 2, 2, 4, 1, 1, 5, 1, 1, 1, 2, 4, 6], [1, 3, 1, 4, 6], [2, 3, 3, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 6], [6], [6], [1, 6], [3, 2, 1, 4, 1, 1, 1, 5, 6], [2, 1, 2, 6], [1, 1, 2, 2, 4, 1, 3, 1, 6], [1, 2, 3, 6], [2, 1, 3, 6], [1, 1, 3, 4, 1, 1, 1, 4, 1, 6], [1, 2, 1, 1, 1, 1, 1, 4, 2, 2, 2, 3, 1, 1, 4, 1, 3, 1, 1, 3, 4, 2, 5, 1, 1, 6], [4, 1, 1, 5, 2, 6], [2, 2, 1, 1, 6], [5, 2, 5, 6], [6], [1, 5, 2, 3, 1, 4, 6], [2, 2, 6], [3, 5, 2, 2, 1, 3, 5, 2, 1, 1, 1, 6], [1, 6], [1, 5, 4, 2, 6], [4, 2, 5, 4, 1, 2, 6], [1, 1, 5, 3, 1, 3, 1, 3, 1, 4, 2, 2, 5, 1, 1, 1, 1, 5, 3, 4, 5, 2, 1, 2, 1, 6], [2, 6], [4, 2, 1, 2, 1, 6], [3, 1, 6], [1, 1, 1, 2, 5, 1, 6], [3, 2, 1, 6], [2, 6], [6], [1, 1, 3, 3, 2, 2, 1, 2, 1, 3, 3, 1, 1, 1, 4, 2, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 1, 4, 6], [2, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "def slice_list_by_number(input_list, number):\n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    result = []\n",
    "    # 현재 하위 리스트를 저장할 임시 리스트 초기화\n",
    "    temp_list = []\n",
    "\n",
    "    # 입력 리스트를 순회하면서 요소를 확인\n",
    "    for item in input_list:\n",
    "        # 특정 숫자를 찾으면 현재까지의 리스트를 결과에 추가하고, 임시 리스트를 초기화\n",
    "        if item == number:\n",
    "            temp_list.append(item)\n",
    "            result.append(temp_list)\n",
    "            temp_list = []\n",
    "        else:\n",
    "            # 특정 숫자가 아닌 경우 임시 리스트에 추가\n",
    "            temp_list.append(item)\n",
    "\n",
    "    # 남은 요소가 있으면 결과에 추가\n",
    "    if temp_list:\n",
    "        result.append(temp_list)\n",
    "\n",
    "    return result\n",
    "\n",
    "# 예시 사용\n",
    "my_list = normalization_x_data\n",
    "number_to_find = 6\n",
    "new_normalization_x_data = slice_list_by_number(my_list, number_to_find)\n",
    "print(new_normalization_x_data)  # 출력: [[1, 2, 3, 4], [5, 4], [6, 7, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52785374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0 ... 0 0 0]\n",
      " [3 2 4 ... 0 0 0]\n",
      " [2 6 0 ... 0 0 0]\n",
      " ...\n",
      " [6 0 0 ... 0 0 0]\n",
      " [1 1 3 ... 1 4 6]\n",
      " [2 2 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 패딩적용하기\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 토큰화된 시퀀스 예시\n",
    "sequences = new_normalization_x_data\n",
    "\n",
    "# pad_sequences 함수를 이용한 패딩 적용\n",
    "# maxlen은 시퀀스의 최대 길이, padding='post'는 뒤쪽으로 패딩 추가\n",
    "padded_x_data = pad_sequences(sequences, maxlen=30, padding='post')\n",
    "\n",
    "print(padded_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5cbbedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6 0 0 ... 0 0 0]\n",
      "  [3 2 4 ... 0 0 0]\n",
      "  [2 6 0 ... 0 0 0]\n",
      "  ...\n",
      "  [6 0 0 ... 0 0 0]\n",
      "  [1 5 2 ... 0 0 0]\n",
      "  [2 2 6 ... 0 0 0]]\n",
      "\n",
      " [[3 2 4 ... 0 0 0]\n",
      "  [2 6 0 ... 0 0 0]\n",
      "  [4 6 0 ... 0 0 0]\n",
      "  ...\n",
      "  [1 5 2 ... 0 0 0]\n",
      "  [2 2 6 ... 0 0 0]\n",
      "  [3 5 2 ... 0 0 0]]\n",
      "\n",
      " [[2 6 0 ... 0 0 0]\n",
      "  [4 6 0 ... 0 0 0]\n",
      "  [4 2 5 ... 0 0 0]\n",
      "  ...\n",
      "  [2 2 6 ... 0 0 0]\n",
      "  [3 5 2 ... 0 0 0]\n",
      "  [1 6 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 2 1 ... 0 0 0]\n",
      "  [1 3 1 ... 0 0 0]\n",
      "  [2 3 3 ... 0 0 0]\n",
      "  ...\n",
      "  [1 1 1 ... 0 0 0]\n",
      "  [3 2 1 ... 0 0 0]\n",
      "  [2 6 0 ... 0 0 0]]\n",
      "\n",
      " [[1 3 1 ... 0 0 0]\n",
      "  [2 3 3 ... 0 0 0]\n",
      "  [6 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [3 2 1 ... 0 0 0]\n",
      "  [2 6 0 ... 0 0 0]\n",
      "  [6 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 3 3 ... 0 0 0]\n",
      "  [6 0 0 ... 0 0 0]\n",
      "  [6 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [2 6 0 ... 0 0 0]\n",
      "  [6 0 0 ... 0 0 0]\n",
      "  [1 1 3 ... 1 4 6]]]\n",
      "[[3 5 2 2 1 3 5 2 1 1 1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 5 4 2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [4 2 5 4 1 2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 5 3 1 3 1 3 1 4 2 2 5 1 1 1 1 5 3 4 5 2 1 2 1 6 0 0 0 0]\n",
      " [2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [4 2 1 2 1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [3 1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 2 5 1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [3 2 1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 3 3 2 2 1 2 1 3 3 1 1 1 4 2 3 1 2 1 2 3 3 2 3 1 1 1 4 6]\n",
      " [2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(numbers_2, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(numbers_2)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(numbers_2)-1:\n",
    "            break\n",
    "        seq_x, seq_y = numbers_2[i:end_ix], numbers_2[end_ix] # end_ix는 포함되지 않는다.\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 숫자 시퀀스 정의\n",
    "numbers_2 = padded_x_data\n",
    "n_steps = 30 # 학습하고싶은 숫자묶음의 크기(발걸음)을 설정합니다. #패딩이용해서 자율적으로 컨드롤할수있도록\n",
    "\n",
    "# 데이터셋 생성\n",
    "X, y = create_dataset(numbers_2, n_steps) #데이터셋 생성 함수 활성화\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13073caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Input 0 of layer \"lstm_6\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 30, 30)\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 30, 30), dtype=int32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 모델 훈련 (내가 생각했을떄 이것은 같은 상황의 반복이므로 에포크를 높게할수록 잘적중될것이다. 그러나 학습하더라도 램덤떄문에 성능개선에 한계가 있다)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_7/bq432lbj2zvb32y8mzswjpy00000gn/T/__autograph_generated_fileeoz_05as.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/pc/anaconda3/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Input 0 of layer \"lstm_6\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 30, 30)\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 30, 30), dtype=int32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 정의\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, 1))) # 50은 층에있는 뉴런의 수\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 훈련을 위해 X를 재구성\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 조기 종료 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련 (내가 생각했을떄 이것은 같은 상황의 반복이므로 에포크를 높게할수록 잘적중될것이다. 그러나 학습하더라도 램덤떄문에 성능개선에 한계가 있다)\n",
    "model.fit(X, y, epochs=500, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# ETA는 0인데 loss는 계속 내려가면 진정한 학습은 안일어나는데 데이터셋에대해서는 학습이 일어나고 있다는건가?\n",
    "# 그것이아니라 ETA가 0인것은 매우짧은 시간안에 학습된다는 시간의 의미였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097a22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8732153"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_numbers_based_on_range(numbers_3, ranges):\n",
    "    new_list = []\n",
    "    for number_3 in numbers_3:\n",
    "        assigned = False\n",
    "        for range_start, range_end, assigned_number in ranges:\n",
    "            if range_start <= number_3 <= range_end:\n",
    "                new_list.append(assigned_number)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            new_list.append(ranges[-1][2])  # 범위에 속하지 않는 경우 마지막 숫자를 할당(range의 마지막 요소 세번째 요소)\n",
    "    return new_list\n",
    "\n",
    "numbers_3 = [22, 115, 208, 1, 155] # 잘작동하나 실험을 학습한 데이터중 하나로하면 실전에서 잘 적용되는지 모르므로 밖에있는 새로운 데이터로 학습시켜보아야한다.\n",
    "ranges = [(1, 51, 1), (51, 101, 2), (101, 151, 3), (151, 201, 4),(201, 251, 5),(251, 301, 6)] # 각 세번째 요소는 할당할 숫자를 의미합니다.\n",
    "normalization_x_input = assign_numbers_based_on_range(numbers_3, ranges)\n",
    "\n",
    "x_input = np.array([normalization_x_input]) # 학습된 데이터에 대해서는 잘작동하게는 했었다.\n",
    "x_input = x_input.reshape((1, n_steps, 1))\n",
    "\n",
    "# 다음 숫자 예측\n",
    "yhat = model.predict(x_input, verbose=1) # verbose 설정에따라 학습상황을 아려줍니다.\n",
    "yhat[0][0]  # 예측된 다음 숫자 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c6f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
