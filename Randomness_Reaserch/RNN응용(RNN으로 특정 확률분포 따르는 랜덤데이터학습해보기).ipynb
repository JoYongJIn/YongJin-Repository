{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e485461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터: [33, 300, 100, 52, 124, 48, 83, 20, 7, 238, 499, 29, 479, 101, 55, 182, 230, 146, 165, 54, 38, 23, 349, 168, 10, 382, 484, 110, 19, 182, 71, 58, 424, 9, 129, 19, 29, 39, 179, 48, 122, 91, 10, 33, 239, 427, 173, 176, 330, 20, 9, 40, 341, 45, 184, 95, 70, 164, 228, 3, 31, 132, 296, 11, 109, 7, 102, 64, 92, 92, 159, 41, 93, 139, 79, 27, 152, 9, 7, 91, 23, 21, 153, 156, 231, 72, 77, 27, 344, 13, 239, 311, 497, 67, 3, 356, 338, 46, 37, 17, 197, 257, 375, 145, 34, 47, 32, 24, 56, 113, 13, 48, 38, 22, 137, 203, 6, 16, 131, 397, 184, 314, 21, 4, 136, 115, 115, 3, 110, 131, 437, 23, 114, 78, 362, 98, 75, 27, 16, 47, 7, 30, 152, 21, 44, 12, 86, 85, 117, 131, 39, 30, 215, 235, 63, 227, 236, 432, 120, 16, 147, 55, 35, 3, 39, 87, 89, 127, 41, 32, 74, 250, 196, 137, 2, 119, 456, 21, 150, 95, 69, 35, 173, 7, 369, 142, 18, 219, 83, 84, 33, 34, 132, 2, 31, 42, 75, 84, 233, 124, 272, 90, 137, 89, 73, 19, 62, 239, 62, 593, 23, 88, 51, 32, 113, 117, 47, 187, 234, 156, 79, 5, 366, 571, 510, 69, 158, 229, 252, 34, 39, 104, 33, 21, 138, 224, 399, 275, 88, 108, 29, 211, 89, 141, 471, 68, 73, 42, 197, 79, 84, 19, 77, 66, 40, 3, 47, 77, 122, 354, 43, 128, 145, 389, 68, 195, 19, 213, 133, 626, 31, 182, 23, 84, 249, 73, 26, 269, 96, 43, 96, 253, 208, 477, 8, 61, 76, 36, 152, 21, 193, 353, 29, 185, 406, 9, 82, 126, 95, 116, 38, 193, 2, 67, 92, 25, 123, 50, 149, 240, 93, 38, 83, 29, 257, 57, 135, 57, 40, 97, 279, 188, 40, 51, 24, 278, 6, 41, 172, 152, 154, 72, 52, 9, 40, 3, 165, 186, 46, 80, 42, 7, 191, 19, 340, 46, 110, 58, 63, 72, 303, 284, 29, 16, 374, 139, 150, 102, 80, 367, 40, 332, 371, 12, 73, 3, 66, 57, 178, 44, 202, 236, 31, 221, 131, 578, 36, 145, 26, 160, 316, 60, 78, 69, 356, 6, 8, 217, 19, 31, 30, 8, 162, 79, 23, 46, 384, 233, 59, 385, 134, 93, 31, 65, 19, 203, 65, 149, 35, 61, 85, 162, 63, 51, 16, 117, 581, 45, 108, 99, 304, 78, 49, 41, 6, 194, 99, 33, 83, 24, 91, 18, 244, 95, 116, 2, 11, 53, 115, 9, 6, 15, 42, 94, 202, 22, 43, 159, 103, 300, 59, 281, 39, 22, 131, 311, 86, 57, 64, 7, 201, 57, 176, 106, 140, 128, 10, 123, 38, 91, 253, 3, 110, 361, 504, 79, 349, 215, 48, 19, 11, 19, 102, 5, 55, 66, 222, 189, 178, 100, 97, 43, 103, 115, 17, 69, 53, 314, 83, 50, 96, 107, 82, 346, 54, 164, 184, 118, 14, 229, 121, 44, 132, 49, 13, 138, 145, 181, 155, 276, 8, 417, 188, 147, 367, 296, 39, 22, 118, 279, 171, 118, 363, 100, 247, 10, 374, 15, 118, 362, 186, 321, 268, 327, 173, 91, 21, 47, 158, 31, 208, 115, 93, 729, 105, 220, 188, 165, 243, 92, 6, 142, 156, 153, 207, 14, 302, 244, 24, 55, 28, 26, 283, 91, 58, 106, 40, 150, 24, 2, 24, 49, 30, 67, 215, 99, 19, 35, 582, 241, 42, 213, 4, 420, 82, 12, 44, 204, 3, 143, 345, 9, 27, 238, 57, 120, 65, 50, 16, 42, 19, 146, 109, 559, 306, 81, 99, 224, 3, 4, 53, 92, 111, 66, 58, 117, 160, 21, 133, 145, 8, 33, 153, 69, 4, 221, 124, 428, 29, 233, 77, 150, 80, 219, 13, 163, 517, 16, 36, 188, 59, 270, 661, 2, 212, 84, 18, 121, 105, 406, 81, 290, 6, 231, 288, 377, 79, 349, 22, 3, 62, 123, 14, 111, 63, 30, 33, 124, 66, 147, 86, 5, 43, 25, 3, 386, 155, 35, 142, 35, 88, 8, 18, 47, 31, 326, 130, 544, 49, 85, 124, 21, 68, 36, 39, 41, 190, 18, 12, 123, 180, 175, 29, 56, 117, 2, 59, 357, 210, 163, 42, 471, 23, 54, 71, 13, 235, 205, 2, 164, 95, 11, 436, 142, 382, 1, 4, 176, 57, 181, 60, 157, 8, 222, 68, 133, 100, 322, 219, 63, 106, 129, 37, 14, 5, 56, 68, 164, 1, 70, 9, 26, 314, 249, 96, 37, 202, 84, 130, 43, 84, 57, 116, 112, 130, 349, 92, 89, 106, 44, 24, 298, 358, 218, 311, 221, 356, 6, 124, 146, 101, 109, 22, 263, 170, 50, 46, 74, 181, 20, 3, 529, 214, 29, 48, 14, 158, 28, 137, 20, 14, 15, 260, 136, 39, 190, 58, 56, 64, 1070, 264, 221, 147, 100, 72, 273, 15, 158, 58, 140, 140, 447, 249, 161, 73, 50, 108, 179, 34, 31, 229, 18, 25, 46, 57, 16, 20, 12, 25, 109, 40, 75, 215, 181, 79, 120, 301, 13, 64, 52, 54, 349, 48, 185, 102, 56, 188, 178, 87, 395, 103, 47, 45, 145, 265, 120, 44, 4, 126, 99, 3, 29, 34, 17, 86, 167, 7, 54, 52, 276, 110, 329, 52, 15, 87, 19, 21, 106, 119, 369, 111, 9, 361, 156, 6, 215, 87, 26, 141, 3, 221, 23, 54, 580, 50, 131, 10, 121, 99, 10, 105, 226, 65, 119, 188, 264, 350, 42, 68, 6, 312, 8, 25, 301, 52, 127, 148, 87, 206, 532, 8, 103, 8, 27, 116, 90, 117, 29, 52, 60, 112, 5, 109, 183, 49, 22, 81, 339, 405, 165, 50, 122, 160, 51, 115, 37, 13, 61, 202, 66, 340, 44, 3, 4, 31, 36, 18, 13, 184, 221, 10, 29, 15, 320, 154, 146, 23, 122, 126, 184, 13, 91, 49, 49, 58, 300, 45, 182, 114, 23]\n",
      "Y 데이터: [0.232, 0.9093, 0.5507, 0.3403, 0.6292, 0.3189, 0.4852, 0.1479, 0.0545, 0.851, 0.9815, 0.2071, 0.9783, 0.5543, 0.356, 0.7668, 0.8412, 0.689, 0.7329, 0.3508, 0.2621, 0.1681, 0.9387, 0.7392, 0.0769, 0.9529, 0.9792, 0.5852, 0.141, 0.7668, 0.4333, 0.3712, 0.9664, 0.0695, 0.6437, 0.141, 0.2071, 0.268, 0.7612, 0.3189, 0.6232, 0.5171, 0.0769, 0.232, 0.8522, 0.9672, 0.7494, 0.7554, 0.9286, 0.1479, 0.0695, 0.2739, 0.9347, 0.3023, 0.7705, 0.5323, 0.4288, 0.7307, 0.8386, 0.0237, 0.2196, 0.6522, 0.9063, 0.0842, 0.5819, 0.0545, 0.5578, 0.4007, 0.521, 0.521, 0.7197, 0.2796, 0.5248, 0.6711, 0.4685, 0.1943, 0.7036, 0.0695, 0.0545, 0.5171, 0.1681, 0.1546, 0.7059, 0.7129, 0.8424, 0.4379, 0.4599, 0.1943, 0.9362, 0.0988, 0.8522, 0.9169, 0.9812, 0.4149, 0.0237, 0.942, 0.9331, 0.3079, 0.2562, 0.1272, 0.7932, 0.872, 0.9502, 0.6865, 0.2381, 0.3134, 0.2259, 0.1747, 0.3611, 0.5951, 0.0988, 0.3189, 0.2621, 0.1614, 0.6658, 0.8029, 0.0469, 0.1201, 0.6494, 0.9582, 0.7705, 0.9189, 0.1546, 0.0315, 0.6631, 0.6015, 0.6015, 0.0237, 0.5852, 0.6494, 0.9697, 0.1681, 0.5983, 0.4642, 0.9448, 0.5434, 0.4512, 0.1943, 0.1201, 0.3134, 0.0545, 0.2134, 0.7036, 0.1546, 0.2967, 0.0915, 0.4974, 0.4934, 0.6078, 0.6494, 0.268, 0.2134, 0.8209, 0.8474, 0.3959, 0.8373, 0.8486, 0.9684, 0.6171, 0.1201, 0.6915, 0.356, 0.2442, 0.0237, 0.268, 0.5014, 0.5093, 0.638, 0.2796, 0.2259, 0.4468, 0.8647, 0.7915, 0.6658, 0.0159, 0.614, 0.974, 0.1546, 0.6988, 0.5323, 0.4242, 0.2442, 0.7494, 0.0545, 0.9478, 0.6789, 0.1341, 0.8266, 0.4852, 0.4893, 0.232, 0.2381, 0.6522, 0.0159, 0.2196, 0.2854, 0.4512, 0.4893, 0.8449, 0.6292, 0.8865, 0.5132, 0.6658, 0.5093, 0.4423, 0.141, 0.391, 0.8522, 0.391, 0.9913, 0.1681, 0.5054, 0.335, 0.2259, 0.5951, 0.6078, 0.3134, 0.776, 0.8462, 0.7129, 0.4685, 0.0392, 0.9465, 0.9896, 0.9831, 0.4242, 0.7175, 0.8399, 0.8668, 0.2381, 0.268, 0.5648, 0.232, 0.1546, 0.6685, 0.8334, 0.9589, 0.8892, 0.5054, 0.5785, 0.2071, 0.8151, 0.5093, 0.6763, 0.9769, 0.4196, 0.4423, 0.2854, 0.7932, 0.4685, 0.4893, 0.141, 0.4599, 0.4102, 0.2739, 0.0237, 0.3134, 0.4599, 0.6232, 0.9411, 0.2911, 0.6408, 0.6865, 0.9555, 0.4196, 0.7899, 0.141, 0.818, 0.6549, 0.9933, 0.2196, 0.7668, 0.1681, 0.4893, 0.8636, 0.4423, 0.1878, 0.8837, 0.5361, 0.2911, 0.5361, 0.8679, 0.8106, 0.978, 0.062, 0.3861, 0.4556, 0.2502, 0.7036, 0.1546, 0.7865, 0.9406, 0.2071, 0.7724, 0.9611, 0.0695, 0.4811, 0.6351, 0.5323, 0.6047, 0.2621, 0.7865, 0.0159, 0.4149, 0.521, 0.1813, 0.6262, 0.3297, 0.6964, 0.8534, 0.5248, 0.2621, 0.4852, 0.2071, 0.872, 0.3662, 0.6604, 0.3662, 0.2739, 0.5398, 0.8927, 0.7778, 0.2739, 0.335, 0.1747, 0.8918, 0.0469, 0.2796, 0.7474, 0.7036, 0.7083, 0.4379, 0.3403, 0.0695, 0.2739, 0.0237, 0.7329, 0.7742, 0.3079, 0.4727, 0.2854, 0.0545, 0.783, 0.141, 0.9341, 0.3079, 0.5852, 0.3712, 0.3959, 0.4379, 0.9114, 0.8969, 0.2071, 0.1201, 0.9498, 0.6711, 0.6988, 0.5578, 0.4727, 0.9469, 0.2739, 0.9298, 0.9486, 0.0915, 0.4423, 0.0237, 0.4102, 0.3662, 0.7593, 0.2967, 0.8013, 0.8486, 0.2196, 0.8293, 0.6494, 0.9902, 0.2502, 0.6865, 0.1878, 0.722, 0.9202, 0.3812, 0.4642, 0.4242, 0.942, 0.0469, 0.062, 0.8238, 0.141, 0.2196, 0.2134, 0.062, 0.7264, 0.4685, 0.1681, 0.3079, 0.9537, 0.8449, 0.3762, 0.954, 0.6577, 0.5248, 0.2196, 0.4055, 0.141, 0.8029, 0.4055, 0.6964, 0.2442, 0.3861, 0.4934, 0.7264, 0.3959, 0.335, 0.1201, 0.6078, 0.9904, 0.3023, 0.5785, 0.5471, 0.9121, 0.4642, 0.3243, 0.2796, 0.0469, 0.7882, 0.5471, 0.232, 0.4852, 0.1747, 0.5171, 0.1341, 0.858, 0.5323, 0.6047, 0.0159, 0.0842, 0.3456, 0.6015, 0.0695, 0.0469, 0.1131, 0.2854, 0.5286, 0.8013, 0.1614, 0.2911, 0.7197, 0.5613, 0.9093, 0.3762, 0.8944, 0.268, 0.1614, 0.6494, 0.9169, 0.4974, 0.3662, 0.4007, 0.0545, 0.7997, 0.3662, 0.7554, 0.5717, 0.6737, 0.6408, 0.0769, 0.6262, 0.2621, 0.5171, 0.8679, 0.0237, 0.5852, 0.9443, 0.9823, 0.4685, 0.9387, 0.8209, 0.3189, 0.141, 0.0842, 0.141, 0.5578, 0.0392, 0.356, 0.4102, 0.8307, 0.7795, 0.7593, 0.5507, 0.5398, 0.2911, 0.5613, 0.6015, 0.1272, 0.4242, 0.3456, 0.9189, 0.4852, 0.3297, 0.5361, 0.5751, 0.4811, 0.9372, 0.3508, 0.7307, 0.7705, 0.6109, 0.106, 0.8399, 0.6202, 0.2967, 0.6522, 0.3243, 0.0988, 0.6685, 0.6865, 0.765, 0.7106, 0.8901, 0.062, 0.9644, 0.7778, 0.6915, 0.9469, 0.9063, 0.268, 0.1614, 0.6109, 0.8927, 0.7454, 0.6109, 0.9452, 0.5507, 0.8614, 0.0769, 0.9498, 0.1131, 0.6109, 0.9448, 0.7742, 0.9233, 0.8828, 0.9269, 0.7494, 0.5171, 0.1546, 0.3134, 0.7175, 0.2196, 0.8106, 0.6015, 0.5248, 0.9971, 0.5683, 0.828, 0.7778, 0.7329, 0.8569, 0.521, 0.0469, 0.6789, 0.7129, 0.7059, 0.8091, 0.106, 0.9107, 0.858, 0.1747, 0.356, 0.2007, 0.1878, 0.8961, 0.5171, 0.3712, 0.5717, 0.2739, 0.6988, 0.1747, 0.0159, 0.1747, 0.3243, 0.2134, 0.4149, 0.8209, 0.5471, 0.141, 0.2442, 0.9905, 0.8546, 0.2854, 0.818, 0.0315, 0.9653, 0.4811, 0.0915, 0.2967, 0.8045, 0.0237, 0.6815, 0.9367, 0.0695, 0.1943, 0.851, 0.3662, 0.6171, 0.4055, 0.3297, 0.1201, 0.2854, 0.141, 0.689, 0.5819, 0.9886, 0.9135, 0.4769, 0.5471, 0.8334, 0.0237, 0.0315, 0.3456, 0.521, 0.5885, 0.4102, 0.3712, 0.6078, 0.722, 0.1546, 0.6549, 0.6865, 0.062, 0.232, 0.7059, 0.4242, 0.0315, 0.8293, 0.6292, 0.9674, 0.2071, 0.8449, 0.4599, 0.6988, 0.4727, 0.8266, 0.0988, 0.7286, 0.984, 0.1201, 0.2502, 0.7778, 0.3762, 0.8847, 0.9949, 0.0159, 0.8166, 0.4893, 0.1341, 0.6202, 0.5683, 0.9611, 0.4769, 0.9017, 0.0469, 0.8424, 0.9001, 0.951, 0.4685, 0.9387, 0.1614, 0.0237, 0.391, 0.6262, 0.106, 0.5885, 0.3959, 0.2134, 0.232, 0.6292, 0.4102, 0.6915, 0.4974, 0.0392, 0.2911, 0.1813, 0.0237, 0.9544, 0.7106, 0.2442, 0.6789, 0.2442, 0.5054, 0.062, 0.1341, 0.3134, 0.2196, 0.9263, 0.6465, 0.9871, 0.3243, 0.4934, 0.6292, 0.1546, 0.4196, 0.2502, 0.268, 0.2796, 0.7813, 0.1341, 0.0915, 0.6262, 0.7631, 0.7534, 0.2071, 0.3611, 0.6078, 0.0159, 0.3762, 0.9425, 0.8136, 0.7286, 0.2854, 0.9769, 0.1681, 0.3508, 0.4333, 0.0988, 0.8474, 0.806, 0.0159, 0.7307, 0.5323, 0.0842, 0.9694, 0.6789, 0.9529, 0.008, 0.0315, 0.7554, 0.3662, 0.765, 0.3812, 0.7152, 0.062, 0.8307, 0.4196, 0.6549, 0.5507, 0.9239, 0.8266, 0.3959, 0.5717, 0.6437, 0.2562, 0.106, 0.0392, 0.3611, 0.4196, 0.7307, 0.008, 0.4288, 0.0695, 0.1878, 0.9189, 0.8636, 0.5361, 0.2562, 0.8013, 0.4893, 0.6465, 0.2911, 0.4893, 0.3662, 0.6047, 0.5918, 0.6465, 0.9387, 0.521, 0.5093, 0.5717, 0.2967, 0.1747, 0.9078, 0.943, 0.8252, 0.9169, 0.8293, 0.942, 0.0469, 0.6292, 0.689, 0.5543, 0.5819, 0.1614, 0.878, 0.7433, 0.3297, 0.3079, 0.4468, 0.765, 0.1479, 0.0237, 0.9855, 0.8195, 0.2071, 0.3189, 0.106, 0.7175, 0.2007, 0.6658, 0.1479, 0.106, 0.1131, 0.8751, 0.6631, 0.268, 0.7813, 0.3712, 0.3611, 0.4007, 0.9998, 0.879, 0.8293, 0.6915, 0.5507, 0.4379, 0.8874, 0.1131, 0.7175, 0.3712, 0.6737, 0.6737, 0.972, 0.8636, 0.7242, 0.4423, 0.3297, 0.5785, 0.7612, 0.2381, 0.2196, 0.8399, 0.1341, 0.1813, 0.3079, 0.3662, 0.1201, 0.1479, 0.0915, 0.1813, 0.5819, 0.2739, 0.4512, 0.8209, 0.765, 0.4685, 0.6171, 0.91, 0.0988, 0.4007, 0.3403, 0.3508, 0.9387, 0.3189, 0.7724, 0.5578, 0.3611, 0.7778, 0.7593, 0.5014, 0.9576, 0.5613, 0.3134, 0.3023, 0.6865, 0.88, 0.6171, 0.2967, 0.0315, 0.6351, 0.5471, 0.0237, 0.2071, 0.2381, 0.1272, 0.4974, 0.7371, 0.0545, 0.3508, 0.3403, 0.8901, 0.5852, 0.9281, 0.3403, 0.1131, 0.5014, 0.141, 0.1546, 0.5717, 0.614, 0.9478, 0.5885, 0.0695, 0.9443, 0.7129, 0.0469, 0.8209, 0.5014, 0.1878, 0.6763, 0.0237, 0.8293, 0.1681, 0.3508, 0.9903, 0.3297, 0.6494, 0.0769, 0.6202, 0.5471, 0.0769, 0.5683, 0.836, 0.4055, 0.614, 0.7778, 0.879, 0.9392, 0.2854, 0.4196, 0.0469, 0.9176, 0.062, 0.1813, 0.91, 0.3403, 0.638, 0.6939, 0.5014, 0.8076, 0.9858, 0.062, 0.5613, 0.062, 0.1943, 0.6047, 0.5132, 0.6078, 0.2071, 0.3403, 0.3812, 0.5918, 0.0392, 0.5819, 0.7687, 0.3243, 0.1614, 0.4769, 0.9336, 0.9608, 0.7329, 0.3297, 0.6232, 0.722, 0.335, 0.6015, 0.2562, 0.0988, 0.3861, 0.8013, 0.4102, 0.9341, 0.2967, 0.0237, 0.0315, 0.2196, 0.2502, 0.1341, 0.0988, 0.7705, 0.8293, 0.0769, 0.2071, 0.1131, 0.9227, 0.7083, 0.689, 0.1681, 0.6232, 0.6351, 0.7705, 0.0988, 0.5171, 0.3243, 0.3243, 0.3712, 0.9093, 0.3023, 0.7668, 0.5983, 0.1681]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def generate_data(num_trials):\n",
    "    trials = []\n",
    "    for _ in range(num_trials):\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            if random.randint(1, 125) == 1:\n",
    "                break\n",
    "        trials.append(count)\n",
    "    return trials\n",
    "\n",
    "x_data = generate_data(1000)\n",
    "\n",
    "def apply_formula(x):\n",
    "    # 여기에 당신의 공식을 적용합니다.\n",
    "    # 예: y = x * 2\n",
    "    y = round(1-math.exp(-x/125),4)\n",
    "    return y\n",
    "\n",
    "def generate_y_list(x_list):\n",
    "    y_list = []\n",
    "    for x in x_list:\n",
    "        y = apply_formula(x)\n",
    "        y_list.append(y)\n",
    "    return y_list\n",
    "\n",
    "# Y 데이터 리스트 생성\n",
    "y_data = generate_y_list(x_data)\n",
    "\n",
    "print(\"X 데이터:\", x_data)\n",
    "print(\"Y 데이터:\", y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4816036",
   "metadata": {},
   "source": [
    "# 1단계 생각( 처음 시도 오류들 발견됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe61de",
   "metadata": {},
   "source": [
    "# Gaussian process 이용하려함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a91a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPy in ./anaconda3/lib/python3.10/site-packages (1.10.0)\r\n",
      "Requirement already satisfied: cython>=0.29 in ./anaconda3/lib/python3.10/site-packages (from GPy) (3.0.5)\r\n",
      "Requirement already satisfied: scipy>=1.3.0 in ./anaconda3/lib/python3.10/site-packages (from GPy) (1.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.7 in ./anaconda3/lib/python3.10/site-packages (from GPy) (1.23.5)\r\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.10/site-packages (from GPy) (1.16.0)\r\n",
      "Requirement already satisfied: paramz>=0.9.0 in ./anaconda3/lib/python3.10/site-packages (from GPy) (0.9.5)\r\n",
      "Requirement already satisfied: decorator>=4.0.10 in ./anaconda3/lib/python3.10/site-packages (from paramz>=0.9.0->GPy) (5.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2963bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 값: [[125.88509367]]\n",
      "예측의 불확실성: [[15456.26135939]]\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "\n",
    "# 리스트를 한 칸씩 뒤로 미루고, 마지막 요소는 제거\n",
    "y_data = x_data[:-1]\n",
    "y_data.insert(0, 0)  # 리스트 시작 부분에 0 추가\n",
    "\n",
    "# 예시 데이터: X는 시도 횟수, Y는 관측된 값\n",
    "X = np.array(x_data).reshape(-1, 1)\n",
    "Y = np.array(y_data).reshape(-1, 1)\n",
    "\n",
    "# Matérn 커널 사용하여 가우시안 프로세스 회귀 모델 생성\n",
    "kernel = GPy.kern.Matern32(input_dim=1)\n",
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "\n",
    "# 모델 최적화\n",
    "model.optimize()\n",
    "\n",
    "# 새로운 데이터에 대한 예측\n",
    "new_X = np.array([[146, 35, 86, 162, 6, 31, 386]])  # 새로운 입력 값\n",
    "predicted_Y, variance = model.predict(new_X)\n",
    "\n",
    "print(\"예측된 값:\", predicted_Y)\n",
    "print(\"예측의 불확실성:\", variance)\n",
    "\n",
    "# 예측 불확실성(분산) 보니 아주 개판이다. 불확실성이 엄청큼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae778ef3",
   "metadata": {},
   "source": [
    "# RNN 이용\n",
    "\n",
    "이렇게하면 문제가 쫙 학습하고 숫자하나보고 나음올 숫자를 맞추는것이기때문에\n",
    "숫자 배열을 통해 다음올 숫자를 고려하지는 못한다. 그러나 단순히 임의 숫자뒤에 어떤숫자가 올지 예측해준다. 이를 통해 일정 특징을 발견할수도있다. 아래 rnn 모델 문법적오류로 실행은 안되지만 위에 가우시안프로세스 보니까 결과 뻔해서 안해본다. 애초에 말이안되는 접근이다 처음 두모델(가우시안, rnn)모델은"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eee31dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Collecting tensorflow-macos==2.14.0\n",
      "  Downloading tensorflow_macos-2.14.0-cp310-cp310-macosx_12_0_arm64.whl (199.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.4.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.2-cp310-cp310-macosx_12_0_universal2.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.20.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.23.5)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (65.6.3)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, opt-einsum, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed astunparse-1.6.3 cachetools-5.3.2 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.2 keras-2.14.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-macos-2.14.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d216c4fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1000 into shape (1,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m next_number \u001b[38;5;241m=\u001b[39m [shifted_x_data]  \u001b[38;5;66;03m# 예측해야 할 다음 숫자\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 데이터 전처리\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(next_number)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(next_number), \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# RNN 모델 구축\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1000 into shape (1,1,1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "original_list = [x_data]\n",
    "new_element = 0  # 리스트 시작 부분에 추가할 새로운 요소\n",
    "\n",
    "# 리스트를 한 칸씩 뒤로 미루고, 새로운 요소를 추가\n",
    "shifted_x_data = [new_element] + original_list[:-1]\n",
    "\n",
    "# 예시 데이터셋 (실제 데이터로 교체 필요)\n",
    "data = [x_data]  # 입력 시퀀스\n",
    "next_number = [shifted_x_data]  # 예측해야 할 다음 숫자\n",
    "\n",
    "# 데이터 전처리\n",
    "X = np.array(data).reshape((len(data), 1, 1))\n",
    "Y = np.array(next_number).reshape((len(next_number), 1))\n",
    "\n",
    "# RNN 모델 구축\n",
    "model = Sequential([\n",
    "    SimpleRNN(50, activation='relu', input_shape=(1, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, Y, epochs=200, verbose=0)\n",
    "\n",
    "# 새로운 데이터에 대한 예측\n",
    "new_data = np.array([21]).reshape((1, 1, 1))\n",
    "predicted_number = model.predict(new_data)\n",
    "print(\"예측된 다음 숫자:\", predicted_number[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2f1cf",
   "metadata": {},
   "source": [
    "# 2단계 생각\n",
    "내가 직접 포아송분포 이용해서 확률을 계산해서 학습시켜서 하려했는데 녹녹치 않아서\n",
    "그냥 숫자들을 리스트로주고 스스로 확률계산하여 숫자배열의 특성을 밝히는 모델을 먼저 찾아보자 찾아보는데 딱히 안보여서 내가 직접 슈도코드 만들어보고(수학적으로) 코드로 만들어서 모델을 만들어본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa9114",
   "metadata": {},
   "source": [
    "# LSTM 이용시도\n",
    "10개씩 쪼개어서 그다음 나오는 숫자를 타겟으로 하여 학습시키는 것도 가능할것같다. 근데 이렇게하면 10개가 채워지기 전에는 예측을 해주지 못한다. 하지만 10개가 넘어가고 부터는 계속 예측가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "965f88a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128.75371"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(numbers, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(numbers)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(numbers)-1:\n",
    "            break\n",
    "        seq_x, seq_y = numbers[i:end_ix], numbers[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 숫자 시퀀스 정의\n",
    "numbers = x_data\n",
    "n_steps = 8 # 학습하고싶은 숫자묶음의 크기(발걸음)을 설정합니다.\n",
    "\n",
    "# 데이터셋 생성\n",
    "X, y = create_dataset(numbers, n_steps)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 훈련을 위해 X를 재구성\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# 예측을 위한 새로운 데이터 포인트\n",
    "x_input = np.array([49, 233, 79, 141, 93, 199, 35, 3])\n",
    "x_input = x_input.reshape((1, n_steps, 1))\n",
    "\n",
    "# 다음 숫자 예측\n",
    "yhat = model.predict(x_input, verbose=1) # verbose 설정에따라 학습상황을 아려줍니다.\n",
    "yhat[0][0]  # 예측된 다음 숫자 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ac30e",
   "metadata": {},
   "source": [
    "# LSTM 숫자 우연인지 몇번 정확히 맞췄다.\n",
    "데이터 세트의 크기를 키우며 어디서 맞추는지 실험해본다. 1.스텝의 크기 2.데이터세트의 크기 조절해볼것 세트 크기 (1000개:120예측 10000:90예측 2000:112예측) 1000개에서 더 근사하게 맞춘다.\n",
    "손좀봐보자\n",
    "정확히 맞춘것은 데이터세트 1000개 숫자배열 크기가 8일때였다\n",
    "###같은 조건으로 반복하여도 예측숫자는 다르게 출력된다.\n",
    "### 계속해보니  확률적으로 근사하여서 맞추는것같긴하다\n",
    "우연이 아니었다 1000개 8개일때 적중하는 숫자있다. 어느정도 맞추는것같다 모델 조금더 손보자 그리고 (나중에 내가 모델 만들어보기도 하자)\n",
    "for문으로 5번정도 시켜서 숫자보기\n",
    "실험 (159 130 170 109 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
